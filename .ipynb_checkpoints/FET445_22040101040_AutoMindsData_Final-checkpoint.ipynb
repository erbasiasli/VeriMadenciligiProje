{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d215f42-a8f0-4ffb-a144-50e369f2ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, accuracy_score, f1_score, \n",
    "    precision_score, recall_score, roc_auc_score, precision_recall_curve, \n",
    "    auc, roc_curve\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "print(\"Kütüphaneler ve Ayarlar Hazır.\")\n",
    "\n",
    "# veri setimizi pandas ile okuyorum\n",
    "try:\n",
    "    df_raw = pd.read_csv('ekip_odevi_ham_veri_30k.csv')\n",
    "    print(f\"Veri seti yüklendi. Boyut: {df_raw.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Hata: Dosya bulunamadı.\")\n",
    "\n",
    "# veri temizliği fonksiyonum\n",
    "# veri setindeki kirli karakterleri temizlemek ve sayısal dönüşümler için fonksiyon yazıyorum\n",
    "\n",
    "def robust_clean(df_input):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # string  kolonları temizliyoruz\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        # para birimi işaretlerini ve virgülleri kaldırıp boşlukları temizliyorum\n",
    "        df[col] = df[col].astype(str).str.replace(r'[£$€,]', '', regex=True).str.strip()\n",
    "        \n",
    "        # \"nan\" veya \"None\" gibi string olarak gelmiş boş değerleri gerçek NaN yapıyorum\n",
    "        df[col] = df[col].replace({'nan': np.nan, 'None': np.nan, '': np.nan})\n",
    "\n",
    "    # sayısal olması gereken ama string görünen kolonları dönüştürüyorum\n",
    "    # errors='coerce' diyerek dönüşemeyenleri NaN yapıyoruz ki kod patlamasın\n",
    "    numeric_candidates = ['price', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "    for col in numeric_candidates:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "if 'df_raw' in locals():\n",
    "    print(\"Veri temizliği ve filtreleme işlemi \")\n",
    "    \n",
    "    df_clean = df_raw.copy()\n",
    "    df_clean = robust_clean(df_clean)\n",
    "    \n",
    "    # tekrar eden satırları siliyorum\n",
    "    ilk_boyut = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
    "    silinen = ilk_boyut - len(df_clean)\n",
    "    \n",
    "    print(f\"- Temizlik tamamlandı.\")\n",
    "    print(f\"- {silinen} adet tekrar eden kayıt silindi.\")\n",
    "    print(f\"- Yeni Veri Seti Boyutu: {df_clean.shape}\")\n",
    "    \n",
    "    # veri tiplerine bakalım\n",
    "    print(\"\\nTemizlik Sonrası Kritik Sütunların Veri Tipleri:\")\n",
    "    print(df_clean[['price', 'mileage', 'tax', 'mpg', 'engineSize']].dtypes)\n",
    "    \n",
    "    display(df_clean.head())\n",
    "else:\n",
    "    print(\"HATA: 'df_raw' bulunamadı.\")\n",
    "\n",
    "#  Veri Hazırlama\n",
    "df_clean['price'] = pd.to_numeric(df_clean['price'], errors='coerce')\n",
    "df_clean = df_clean.dropna(subset=['price'])\n",
    "\n",
    "print(\"IQR ile Aykırı Değer Temizliği Başlıyor.\")\n",
    "filtre_oncesi = len(df_clean)\n",
    "\n",
    "#  IQR Hesaplama\n",
    "Q1 = df_clean['price'].quantile(0.25)\n",
    "Q3 = df_clean['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "#  Sınırları Belirleme ve Negatif Değer Kontrolü\n",
    "# İstatistiksel alt sınır negatif çıkarsa, onu 100 (veya 0) olarak güncelle\n",
    "hesaplanan_alt = Q1 - 1.5 * IQR\n",
    "alt_sinir = max(100, hesaplanan_alt) # Fiyat 100'den küçük olamaz \n",
    "ust_sinir = Q3 + 1.5 * IQR\n",
    "\n",
    "#  Filtreleme Uygulaması\n",
    "df_clean = df_clean[(df_clean['price'] >= alt_sinir) & (df_clean['price'] <= ust_sinir)]\n",
    "\n",
    "#  Sonuçları Yazdırma\n",
    "silinen_adet = filtre_oncesi - len(df_clean)\n",
    "print(f\"- Hesaplanan İstatistiksel Alt Sınır: {hesaplanan_alt:.2f}\")\n",
    "print(f\"- Uygulanan Mantıksal Alt Sınır: {alt_sinir:.2f}\")\n",
    "print(f\"- Üst Sınır: {ust_sinir:.2f}\")\n",
    "print(f\"- Filtreleme sonucu {silinen_adet} adet aykırı veri elendi.\")\n",
    "print(f\"- Analize hazır veri boyutu: {df_clean.shape}\")\n",
    "\n",
    "# 6. Temizlik Sonrası Görselleştirme\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=df_clean['price'], color='lightgreen')\n",
    "plt.title('Mantıksal Sınırlarla Temizlenmiş Fiyat Dağılımı', fontsize=12)\n",
    "plt.xlabel('Fiyat')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# fiyat dağılım grafiğine bakıyorum\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['price'], bins=50, kde=True, color='teal')\n",
    "plt.title('Araç Fiyatlarının Dağılımı')\n",
    "plt.xlabel('Fiyat (£)')\n",
    "plt.ylabel('Araç Sayısı')\n",
    "plt.axvline(df_clean['price'].mean(), color='red', linestyle='--', label='Ortalama Fiyat')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ADVANCED modeller ile veri hazırlığı \n",
    "print(\"Advanced modeller için veri hazırlanıyor.\")\n",
    "\n",
    "df_adv = df_clean.copy()\n",
    "#label encoding\n",
    "cat_cols = df_adv.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df_adv[col] = df_adv[col].astype('category').cat.codes#her kelimeye bir sayı atar.\n",
    "\n",
    "X_adv = df_adv.drop('price', axis=1) #özellikler\n",
    "y_adv = df_adv['price'] #hedef\n",
    "\n",
    "X_train_adv, X_test_adv, y_train_adv, y_test_adv = train_test_split(X_adv, y_adv, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Advanced veri seti ayrıldı:\")\n",
    "print(f\"- Eğitim Seti (Train): {X_train_adv.shape}\")\n",
    "print(f\"- Test Seti (Test)   : {X_test_adv.shape}\")\n",
    "\n",
    "#  ADVANCED modellerin eğitimi \n",
    "\n",
    "if 'X_train_adv' not in locals() or 'y_train_adv' not in locals():\n",
    "    raise ValueError(\"Advanced eğitim verisi bulunamadı\")\n",
    "    \n",
    "print(\"Advanced modeller Hyperparameter Tuning ile eğitiliyor .\")\n",
    "\n",
    "# Modeller ve denenecek parametreler \n",
    "advanced_models = {\n",
    "    \"Random Forest\": (RandomForestRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200], #dikilecek ağaç sayısı\n",
    "        'model__max_depth': [None, 10], # derinlik \n",
    "        'model__min_samples_split': [2, 5] #Bir dalın bölünmesi için gereken min. \n",
    "    }),\n",
    "    \"XGBoost\": (XGBRegressor(random_state=42), {\n",
    "        'model__n_estimators': [100, 200], #hata düzetlme işleminin kaç kez tekrarlanacağı \n",
    "        'model__learning_rate': [0.05, 0.1], #Her adımda modelin hatalardan ne kadar hızlı ders çıkaracağını belirler.\n",
    "        'model__max_depth': [3, 6]\n",
    "    })\n",
    "}\n",
    "\n",
    "advanced_results = []\n",
    "best_params_report = {}\n",
    "\n",
    "for name, (model, params) in advanced_models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')), #boşluklar dolar\n",
    "        ('scaler', StandardScaler()), #veri ölçeklenir\n",
    "        ('model', model) #en son model girer \n",
    "    ])\n",
    "    \n",
    "    # GridSearchCV ile optimum parametreleri buluyoruz\n",
    "    grid_search = GridSearchCV(pipe, params, cv=3, scoring='r2', n_jobs=-1)\n",
    "    #cv=3 Veriyi 3 parçaya böler. 2 parçayla eğitir, 1 parçayla test eder.\n",
    "    grid_search.fit(X_train_adv, y_train_adv)\n",
    "    \n",
    "    # En iyi modeli alıyoruz\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params_report[name] = grid_search.best_params_\n",
    "    \n",
    "    # Tahmin etme\n",
    "    y_pred = best_model.predict(X_test_adv)\n",
    "    \n",
    "    # Skorlama \n",
    "    r2 = r2_score(y_test_adv, y_pred)\n",
    "    mae = mean_absolute_error(y_test_adv, y_pred)\n",
    "    mse = mean_squared_error(y_test_adv, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    advanced_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Yöntem\": \"GridSearch Optimized\",\n",
    "        \"R2 Skoru\": r2, \n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Optimum Parametreler\": str(grid_search.best_params_)\n",
    "    })\n",
    "\n",
    "# Sonuç tablosu \n",
    "df_adv_results = pd.DataFrame(advanced_results)\n",
    "print(\"\\nAdvanced Model Sonuçları (Optimum Parametreler):\")\n",
    "display(df_adv_results.sort_values(by=\"R2 Skoru\", ascending=False).style.background_gradient(cmap=\"Blues\"))\n",
    "\n",
    "# Rapor için çıktı\n",
    "print(\"\\n EN OPTİMUM PARAMETRELER\")\n",
    "for model_name, p in best_params_report.items():\n",
    "    print(f\"{model_name}: {p}\")\n",
    "\n",
    "# feature engineering\n",
    "# veriden yeni anlamlı özellikler türetiyoruz. \n",
    "\n",
    "if 'df_clean' in locals():\n",
    "    df_eng = df_clean.copy()\n",
    "else:\n",
    "    print(\"df_clean bulunamadı, işlemler atlanıyor.\")\n",
    "    df_eng = pd.DataFrame()\n",
    "\n",
    "df_eng['mileage'] = pd.to_numeric(df_eng['mileage'], errors='coerce')\n",
    "print(\"Özellik mühendisliği başlıyor.\")\n",
    "\n",
    "# yeni özellikler türetiyorum\n",
    "df_eng['age'] = 2025 - df_eng['year']\n",
    "df_eng['avg_km_per_year'] = df_eng['mileage'] / df_eng['age'].replace(0, 1)\n",
    "print(\"Yeni özellikler eklendi: 'age', 'avg_km_per_year'\")\n",
    "\n",
    "# türetme sonrası temizlik\n",
    "df_eng = df_eng.drop(columns=['year'])\n",
    "limit = len(df_eng) * 0.5\n",
    "df_eng = df_eng.dropna(thresh=limit, axis=1) #yarısı dolu değilse o sütunu sil.\n",
    "df_eng.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#inf pozitif sonsuzluk - negatif sonsuzluk aracın yaşı 0  ise hata vermesin diye Nan yapma\n",
    "\n",
    "kritik_sutunlar = ['price', 'age', 'mileage', 'avg_km_per_year']\n",
    "mevcut_kritik = [col for col in kritik_sutunlar if col in df_eng.columns]\n",
    "df_eng.dropna(subset=mevcut_kritik, inplace=True)\n",
    "\n",
    "print(f\"İşlem sonrası veri boyutu: {df_eng.shape}\")\n",
    "print(\"\\nYeni özelliklerle veri seti örneği:\")\n",
    "display(df_eng[['price', 'age', 'mileage', 'avg_km_per_year']].head())\n",
    "\n",
    "# Korelasyon Analizi (Düzeltilmiş)\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_cols = df_eng.select_dtypes(include=np.number)\n",
    "sns.heatmap(numeric_cols.corr(), annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Özellikler Arasındaki İlişki (Korelasyon Matrisi)')\n",
    "plt.show()\n",
    "\n",
    "## modelin kategorik verileri daha iyi anlaması için One-Hot Encoding yapıyoruz.\n",
    "print(\"One-Hot Encoding yapılıyor.\")\n",
    "\n",
    "if 'df_eng' in locals() and len(df_eng) > 0:\n",
    "    df_model = df_eng.copy()\n",
    "else:\n",
    "    df_model = df_clean.copy()\n",
    "\n",
    "df_encoded = pd.get_dummies(df_model, drop_first=True)\n",
    "#get_dumines 0 ve 1 lerden oluşan yeni sütuna dönüştürür.\n",
    "X = df_encoded.drop('price', axis=1)\n",
    "y = df_encoded['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nVeri seti başarıyla hazırlandı ve bölündü:\")\n",
    "print(f\"- Eğitim Seti Boyutu (X_train): {X_train.shape}\")\n",
    "print(f\"- Test Seti Boyutu  (X_test) : {X_test.shape}\")\n",
    "\n",
    "#  ADVANCED modellerin farklı işlemlerde karşılaştırılamsı\n",
    "\n",
    "print(\"Advanced modeller Tuning ile farklı veri setleri üzerinde test ediliyor.\")\n",
    "\n",
    "# Ölçeklendirme ve Imputer (Ön hazırlık)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(imputer.fit_transform(X_train))\n",
    "X_test_scaled = scaler.transform(imputer.transform(X_test))\n",
    "\n",
    "# SelectKBest (10)\n",
    "selector = SelectKBest(score_func=f_regression, k=10)\n",
    "X_train_sel = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_sel = selector.transform(X_test_scaled)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "datasets = {\n",
    "    \"1. Tüm Özellikler (Scaled)\": (X_train_scaled, X_test_scaled),\n",
    "    \"2. SelectKBest (10 Özellik)\": (X_train_sel, X_test_sel),\n",
    "    \"3. PCA (İndirgenmiş)\": (X_train_pca, X_test_pca)\n",
    "}\n",
    "\n",
    "tuning_params = {\n",
    "    \"Random Forest\": {'n_estimators': [100, 200], 'max_depth': [10, None]},\n",
    "    \"XGBoost\": {'n_estimators': [100, 200], 'learning_rate': [0.1]}\n",
    "}\n",
    "\n",
    "advanced_final_results = []\n",
    "\n",
    "for model_name, model_obj in {\"Random Forest\": RandomForestRegressor(random_state=42), \n",
    "                              \"XGBoost\": XGBRegressor(random_state=42)}.items():\n",
    "    for data_name, (X_tr, X_te) in datasets.items():\n",
    "        print(f\"Eğitiliyor: {model_name} - {data_name}\")\n",
    "        \n",
    "        # Hyperparameter Tuning\n",
    "        grid = GridSearchCV(model_obj, tuning_params[model_name], cv=3, n_jobs=-1)\n",
    "        grid.fit(X_tr, y_train)\n",
    "        \n",
    "        best_m = grid.best_estimator_\n",
    "        preds = best_m.predict(X_te)\n",
    "        \n",
    "        r2 = r2_score(y_test, preds)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "        \n",
    "        advanced_final_results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Yöntem\": data_name,\n",
    "            \"R2 Score\": r2,\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse, \n",
    "            \"Özellik Sayısı\": X_tr.shape[1],\n",
    "            \"Optimum Parametre\": str(grid.best_params_)\n",
    "        })\n",
    "\n",
    "df_adv_final_results = pd.DataFrame(advanced_final_results)\n",
    "display(df_adv_final_results.sort_values(by=\"R2 Score\", ascending=False))\n",
    "\n",
    "#  PYTORCH derin öğrenme modelleri\n",
    "\n",
    "# 1. Y (Fiyat) Değişkenini Ölçeklendirme Negatif R2 almasını engelledim.\n",
    "y_scaler = StandardScaler()\n",
    "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "y_train_scaled_np = y_scaler.fit_transform(y_train_reshaped)\n",
    "# çok büyük sayısal değerlerle  eğitilirken matematiksel olarak kararsızlaşabilir.\n",
    "# skorunun negatif çıkmasına neden olur. \n",
    "#Çıktıyı küçülterek modelin daha hızlı ve doğru öğrenmesini sağlıyoruz.\n",
    "\n",
    "# Tensorları Hazırlama\n",
    "X_train_pt = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_pt = torch.tensor(y_train_scaled_np, dtype=torch.float32)\n",
    "X_test_pt = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Modelleri Tanımlama \n",
    "class ModelV1(nn.Module): #3 katmanlı basit bir ağ.\n",
    "    def __init__(self, input_dim):\n",
    "        super(ModelV1, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1))\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class ModelV2(nn.Module): #Daha derin ve güvenli bir ağ\n",
    "    def __init__(self, input_dim):\n",
    "        super(ModelV2, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(input_dim, 128), nn.ReLU(), nn.Dropout(0.2), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 32), nn.ReLU(), nn.Linear(32, 1))\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def train_pytorch_model(model, X, y, epochs=150, lr=0.001):\n",
    "    #epochs devir sayısı.tüm veri setini baştan sona kaç kez göreceğidir.\n",
    "    #lr modelin bir hatadan ne kadar büyük ders çıkaracağını belirler.bir adım büyüklüğü \n",
    "    criterion = nn.MSELoss() #hata ölçer tahmin edilen fiyat ile gerçek fiyat arasındakş farkın karesi alınır.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) #Modelin ağırlıklarını hatayı azaltacak şekilde günceller.\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad() #hafızayı sıfırlar.\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward() #Hangi nöronun ne kadar suçlu olduğunu hesaplar.\n",
    "        optimizer.step() #Nöronların ağırlıklarını bir adım ileri taşır.\n",
    "    return model\n",
    "\n",
    "advanced_final_results = [m for m in advanced_final_results if m['Yöntem'] != \"PyTorch DL\"]\n",
    "\n",
    "input_dim = X_train_pt.shape[1]\n",
    "pt_models = {\"PyTorch MLP v1 (Standart)\": ModelV1(input_dim), \"PyTorch Deep v2 (Gelişmiş)\": ModelV2(input_dim)}\n",
    "\n",
    "print(\"PyTorch modelleri eğitiliyor.\")\n",
    "for name, model_obj in pt_models.items():\n",
    "    trained_model = train_pytorch_model(model_obj, X_train_pt, y_train_pt)\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tahmin al ve inverse transform ile gerçek fiyatlara (£) geri dön\n",
    "        preds_scaled = trained_model(X_test_pt).numpy()\n",
    "        preds = y_scaler.inverse_transform(preds_scaled).flatten()\n",
    "        #Model bize ölçeklenmiş (0.5, -0.2 gibi) değerler verir.\n",
    "        #Biz bunları y_scaler kullanarak tekrar gerçek fiyat birimine  çeviriyoruz.\n",
    "    \n",
    "    # Metrikleri Hesapla\n",
    "    r = r2_score(y_test, preds)\n",
    "    m = mean_absolute_error(y_test, preds)\n",
    "    ma = mean_absolute_percentage_error(y_test, preds)\n",
    "    \n",
    "    advanced_final_results.append({\n",
    "        \"Model\": name, \"Yöntem\": \"PyTorch DL\", \"R2 Score\": r, \"MAE\": m,\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, preds)), \"MAPE\": ma,\n",
    "        \"saved_preds\": preds, \"Optimum Parametre\": \"Epoch: 150, LR: 0.001, Y-Scaled\"\n",
    "    })\n",
    "\n",
    "print(\"İşlem Tamamlandı.\")\n",
    "\n",
    "#  pytorch modelleri karşılaştırması \n",
    "df_pytorch_only = df_metrics[df_metrics['Yöntem'] == 'PyTorch DL'].copy()\n",
    "\n",
    "# Seçtiğimiz bu veriyi \"melt\" ediyoruz\n",
    "df_melted_pt = df_pytorch_only.melt(id_vars='Model', \n",
    "                                   value_vars=['R2 Score', 'MAPE'], \n",
    "                                   var_name='Metrik', \n",
    "                                   value_name='Değer')\n",
    "\n",
    "#  Görselleştirme\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Metrik', y='Değer', hue='Model', data=df_melted_pt, palette='magma')\n",
    "\n",
    "plt.title('PyTorch V1 vs V2 Performans Karşılaştırması', fontsize=14)\n",
    "plt.ylabel('Skor / Hata Payı')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# TÜM MODELLERİN KARŞILAŞTIRILMASI \n",
    "\n",
    "#  Vize skorlarını tanımlıyoruz.\n",
    "vize_base_results = [\n",
    "    {\"Model\": \"Decision Tree (Base)\", \"Yöntem\": \"Vize Ödevi\", \"R2 Score\": 0.886618, \"MAE\": 1825.328, \"RMSE\": np.nan, \"MAPE\": np.nan},\n",
    "    {\"Model\": \"Bayesian Ridge (Base)\", \"Yöntem\": \"Vize Ödevi\", \"R2 Score\": 0.708180, \"MAE\": 3550.245, \"RMSE\": np.nan, \"MAPE\": np.nan}\n",
    "]\n",
    "\n",
    "# Üç farklı kaynaktan verileri birleştiriyoruz\n",
    "#  Vize Sonuçları\n",
    "df_vize = pd.DataFrame(vize_base_results)\n",
    "\n",
    "#  Hücre 12 ve 13'teki karşılaştırmalı sonuçlar (PCA, SelectKBest, PyTorch vb.)\n",
    "df_advanced = pd.DataFrame(advanced_final_results)\n",
    "\n",
    "#  HÜCRE 8'DEKİ YÜKSEK SKORLU SONUÇLAR (0.94 alan XGBoost burada)\n",
    "# Not: advanced_results listesindeki sütun adı \"R2 Skoru\" ise onu \"R2 Score\" olarak düzeltiyoruz\n",
    "df_high_scores = pd.DataFrame(advanced_results)\n",
    "if 'R2 Skoru' in df_high_scores.columns:\n",
    "    df_high_scores = df_high_scores.rename(columns={'R2 Skoru': 'R2 Score'})\n",
    "if 'Yöntem' not in df_high_scores.columns:\n",
    "    df_high_scores['Yöntem'] = \"Ham Veri (Label Encoded)\"\n",
    "\n",
    "# 3. TÜM DENEMELERİ TEK BİR TABLODA TOPLA\n",
    "df_grand_final = pd.concat([df_vize, df_advanced, df_high_scores], ignore_index=True)\n",
    "\n",
    "# 4. HER MODELİN SADECE EN İYİ HALİNİ SEÇ (6 Model Kalacak)\n",
    "# Aynı model ismine sahip olanlardan R2 skoru en yüksek olanı tutuyoruz\n",
    "df_champions = df_grand_final.sort_values(by=\"R2 Score\", ascending=False).drop_duplicates(subset=[\"Model\"])\n",
    "\n",
    "# TABLOYU GÖSTER (Sıralı ve Renkli)\n",
    "print(\"\\n MODELİN EN İYİ PERFORMANS KARŞILAŞTIRMASI \")\n",
    "display(df_champions.sort_values(by=\"R2 Score\", ascending=False).style\n",
    "    .highlight_max(subset=['R2 Score'], color='lightgreen') \n",
    "    .format({\"R2 Score\": \"{:.4f}\", \"MAE\": \"{:.2f}\", \"MAPE\": \"{:.4f}\"}, na_rep=\"-\"))\n",
    "\n",
    "\n",
    "\n",
    "#  görselleştirme\n",
    "plt.figure(figsize=(12, 8))\n",
    "df_champions = df_champions.sort_values(by='R2 Score', ascending=True) # Grafikte en iyi en üstte çıksın diye\n",
    "ax = sns.barplot(x='R2 Score', y='Model', data=df_champions, palette='viridis')\n",
    "\n",
    "# en yüksek skoru bul ve dikey çizgi çek\n",
    "max_r2 = df_champions['R2 Score'].max()\n",
    "plt.axvline(x=max_r2, color='red', linestyle='--', linewidth=2, label=f'En Yüksek Skor: {max_r2:.4f}')\n",
    "\n",
    "# Barların üzerine değer yazma\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_width():.4f}\", (p.get_width(), p.get_y() + p.get_height()/2.),\n",
    "                ha='left', va='center', xytext=(5, 0), textcoords='offset points', fontweight='bold')\n",
    "\n",
    "plt.title('Modellerin En Başarılı Konfigürasyonları Karşılaştırması', fontsize=15)\n",
    "plt.xlabel('R2 Score (Maksimum Başarı)', fontsize=12)\n",
    "plt.xlim(min(df_champions['R2 Score']) - 0.05, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Gerçek vs tahmin analizi\n",
    "\n",
    "#  tahmin verisi olan modelleri filtreleyelim\n",
    "df_with_preds = df_grand_final.dropna(subset=['saved_preds'])\n",
    "\n",
    "# eğer liste boş değilse en yüksek R2 skoruna sahip olanı bulalım\n",
    "if not df_with_preds.empty:\n",
    "    # R2 skoruna göre en iyiyi bul\n",
    "    best_row = df_with_preds.sort_values(by=\"R2 Score\", ascending=False).iloc[0]\n",
    "    \n",
    "    best_model_name = best_row['Model']\n",
    "    best_preds = best_row['saved_preds']\n",
    "    \n",
    "    #  görselleştirme\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Gerçek değerler ve tahminleri çizdir\n",
    "    plt.scatter(y_test, best_preds, alpha=0.4, color='teal', label='Tahminler')\n",
    "    \n",
    "    # Mükemmel tahmin çizgisini ekle kırmızı\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3, label='İdeal Hat')\n",
    "    \n",
    "    plt.title(f'En İyi Model Performansı: {best_model_name}\\n(Gerçek Değerler vs Tahminler)', fontsize=14)\n",
    "    plt.xlabel('Gerçek Araç Fiyatları (£)', fontsize=12)\n",
    "    plt.ylabel('Modelin Tahmin Ettiği Fiyatlar (£)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Hata: Çizdirilecek tahmin verisi bulunamadı.\")\n",
    "\n",
    "\n",
    "\n",
    "# En iyi modelin hatalarını hesaplıyoruz \n",
    "errors = y_test - best_preds\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Sol: Hata Dağılımı\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(errors, kde=True, color='darkviolet')\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title('Model Hatalarının Dağılımı (Residual Distribution)')\n",
    "\n",
    "# Sağ: Hataların Gerçek Değerlere Göre Dağılımı\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, errors, alpha=0.3, color='blue')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Hata Sapma Analizi')\n",
    "plt.xlabel('Gerçek Fiyat')\n",
    "plt.ylabel('Hata Miktarı')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Araç fiyatını en çok etkileyenler \n",
    "\n",
    "# özellik isimlerini içeren  yöntemiyle eğitilmiş en iyi modeli bulalım\n",
    "target_method = \"1. Tüm Özellikler (Scaled)\"\n",
    "df_filtered = df_grand_final[df_grand_final['Yöntem'] == target_method]\n",
    "\n",
    "if not df_filtered.empty:\n",
    "    # Bu yöntemle eğitilmiş en iyi modeli (XGBoost veya RF) seçiyoruz\n",
    "    best_row = df_filtered.sort_values(by=\"R2 Score\", ascending=False).iloc[0]\n",
    "    best_model_name = best_row['Model']\n",
    "    \n",
    "    # Eğer best_m hala o modelse (Scaled ile eğitilen en son modelse) çalışacaktır.\n",
    "    # Aksi takdirde, Scaled veri setiyle eğitilen modeli tekrar hızlıca fit etmeliyiz:\n",
    "    \n",
    "    print(f\"Analiz ediliyor: {best_model_name} ({target_method})\")\n",
    "    \n",
    "    if \"XGBoost\" in best_model_name:\n",
    "        analysis_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    else:\n",
    "        analysis_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    \n",
    "    analysis_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # önem skorlarını al ve X_train sütunlarıyla eşleştir\n",
    "    # X_train_scaled sütun sayısı ile X_train.columns sayısının aynı olduğundan emin oluyoruz\n",
    "    importances = analysis_model.feature_importances_\n",
    "    \n",
    "    # Hata almamak için sütun sayısını kontrol ediyoruz\n",
    "    column_names = X_train.columns if len(X_train.columns) == len(importances) else [f\"Feature_{i}\" for i in range(len(importances))]\n",
    "    \n",
    "    feat_importances = pd.Series(importances, index=column_names).nlargest(10)\n",
    "\n",
    "    #  görselleştirme\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feat_importances.sort_values().plot(kind='barh', color='salmon')\n",
    "    plt.title(f'Araç Fiyatını Belirleyen En Önemli 10 Faktör\\n({best_model_name} Analizi)', fontsize=14)\n",
    "    plt.xlabel('Önem Skoru (Importance Score)', fontsize=12)\n",
    "    plt.ylabel('Araç Özellikleri', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    top_feature = feat_importances.idxmax()\n",
    "    print(f\" Modelimiz araç fiyatını etkileyen en kritik faktörün '{top_feature}' olduğunu saptamıştır.\")\n",
    "else:\n",
    "    print(\"Hata: 'Tüm Özellikler (Scaled)' yöntemiyle eğitilmiş model bulunamadı.\")\n",
    "\n",
    "segment_order = [\"1. Çok Ucuz\", \"2. Ucuz\", \"3. Normal\", \"4. Pahalı\", \"5. Çok Pahalı\"]\n",
    "my_palette = sns.color_palette(\"RdYlGn_r\", n_colors=5)\n",
    "color_map = dict(zip(segment_order, my_palette))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "#  noktaları Çizdirme\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Segment', \n",
    "                hue_order=segment_order,\n",
    "                palette=color_map, \n",
    "                s=70, alpha=0.5, edgecolor='w')\n",
    "\n",
    "# merkezleri kendi renklerinde çizdirme\n",
    "for segment in segment_order:\n",
    "    # O segmente ait verilerin merkezini hesapla\n",
    "    subset = df_pca[df_pca['Segment'] == segment]\n",
    "    if not subset.empty:\n",
    "        centroid_x = subset['PC1'].mean()\n",
    "        centroid_y = subset['PC2'].mean()\n",
    "        \n",
    "        # merkezin rengini paletten alıyoruz\n",
    "        current_color = color_map[segment]\n",
    "        \n",
    "        plt.scatter(centroid_x, centroid_y, \n",
    "                    marker='X', \n",
    "                    s=500,               \n",
    "                    color=current_color, \n",
    "                    edgecolor='black',   \n",
    "                    linewidth=2,\n",
    "                    label=f'{segment} Merkezi',\n",
    "                    zorder=15)           \n",
    "\n",
    "plt.title('PCA Düzleminde Renkli Küme Merkezleri ve Araç Dağılımı', fontsize=16)\n",
    "plt.xlabel('Ana Bileşen 1 (PC1)', fontsize=12)\n",
    "plt.ylabel('Ana Bileşen 2 (PC2)', fontsize=12)\n",
    "plt.legend(title=\"Segmentler ve Merkezleri\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# EN BAŞARILI MODEL VE TEKNİK ANALİZİ\n",
    "# * Projenin en başarılı modeli, 'Tüm Özellikler (Scaled)' yöntemiyle eğitilen ve \n",
    "#   hiperparametreleri optimize edilen XGBOOST modelidir (R²: 0.9385). \n",
    "# * Bu model, vize dönemindeki en iyi model olan Decision Tree'nin (%88) başarısını \n",
    "#   yaklaşık %6 oranında artırmıştır. \n",
    "# * MAE (Ortalama Mutlak Hata) değeri 1575.20 birime düşürülerek, araç fiyat tahminlerindeki \n",
    "#   ortalama sapma payı minimize edilmiştir.\n",
    "\n",
    "# * Vize Ödevi (Base Models): Decision Tree (0.88) ve Bayesian Ridge (0.70)\n",
    "# * Final Projesi (Advanced Models): XGBoost (0.938), Random Forest (0.936), PyTorch (0.928)\n",
    "# *  Basit modellerden karmaşık topluluk (ensemble) ve derin öğrenme modellerine \n",
    "#   geçiş, tahmin gücünde %30'a varan (Bayesian Ridge'e kıyasla) devasa bir iyileşme sağlamıştır.\n",
    "\n",
    "\n",
    "\n",
    "# * ÖZELLİK ÖLÇEKLENDİRME (Scaled): Modellerin en yüksek performansı 'Tüm Özellikler (Scaled)' \n",
    "#   ile verdiği görülmüştür. Bu durum, verideki tüm değişkenlerin (age, engineSize vb.) \n",
    "#   fiyat üzerinde değerli bilgiler taşıdığını kanıtlamaktadır.\n",
    "# * BOYUT İNDİRGEME (PCA): PCA yöntemi özellik sayısını 173'e düşürmesine rağmen 0.93 R² \n",
    "#   gibi oldukça yüksek bir başarısını korumuştur. Bu, verinin daha az boyutta da \n",
    "#   yüksek temsil kabiliyetine sahip olduğunu göstermektedir.\n",
    "# * ÖZELLİK SEÇİMİ (SelectKBest): Sadece en önemli 10 özellik kullanıldığında bile \n",
    "#   0.89 R² başarısına ulaşılması, modelin 'öz' değişkenleri (Model Yılı, Motor Gücü vb.) \n",
    "#   çok iyi ayırt edebildiğini ispatlamaktadır.\n",
    "\n",
    "# DERİN ÖĞRENME (PYTORCH) SONUÇLARI\n",
    "# * 'PyTorch Deep v2 (Gelişmiş)' modelimiz 0.9281 R² ve 0.0986 MAPE (Yüzdesel Hata) \n",
    "#   skoruyla klasik ML modellerine yakın, oldukça stabil bir performans sergilemiştir. \n",
    "# * %9.8'lik MAPE değeri, modelimizin araç fiyatlarını ortalama %90 doğruluk oranıyla \n",
    "#   tahmin edebilecek profesyonel bir olgunlukta olduğunu göstermektedir\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
